# Dataset for Humanoids Using Posture Estimation AI

## プロジェクト概要
ヒューマノイドロボット向けの動作学習やシミュレーションに活用できるデータセットを、姿勢推定AI（2D/3D）を用いて画像・動画ファイルから自動生成するためのリポジトリです。データクレンジングからアノテーション整形、フォーマット統合までの一連のパイプラインを構築することを目的とします。

## 主な目標
- 既存の画像・動画アーカイブから人間のポーズ情報を抽出し、骨格データとして保存する。
- ユースケース別（歩行、作業動作、ジェスチャーなど）に分類可能なラベル設計を行う。
- ロボットシミュレータや強化学習環境で取り扱いやすいフォーマット（JSON、CSV、ROS bag など）へ変換する。
- 再現性の高いパイプラインを構築し、データ更新時も自動的に処理できる自動化スクリプトを提供する。
- 高価なセンサーなどの用意無しに独自のデータセットを比較的簡単に作成することを目標とする。

## 想定技術スタック
- **姿勢推定**: MediaPipe, OpenPose, MoveNet, Detectron2 などのモデルと推論スクリプト
- **前処理/管理**: Python, PyTorch/TensorFlow, OpenCV, NumPy, Pandas
- **ワークフロー自動化**: Prefect, Airflow, Dagster などのワークフローエンジン（必要に応じて）
- **データ保存形式**: JSON（骨格データ）, CSV（メタ情報）, NPZ/Parquet（高速アクセス用）

## データフロー（案）
1. **入力収集**: Raw の画像・動画を `data/raw/` に配置
2. **前処理**: 解像度統一、背景差分、品質フィルタを `scripts/preprocess.py` で実行
3. **姿勢推定**: 推論スクリプトで骨格キーポイントを抽出し `data/processed/` に保存
4. **アノテーション整形**: キーポイントをヒューマノイド座標系に正規化し、ラベルと紐付け
5. **出力生成**: フォーマット別に `data/export/` へ書き出し
6. **品質管理**: 可視化ダッシュボードや統計量で品質評価

## 推奨ディレクトリ構成（初期案）
```
├── README.md
├── data/
│   ├── raw/
│   ├── interim/
│   ├── processed/
│   └── export/
├── notebooks/
├── scripts/
│   ├── preprocess.py
│   ├── pose_estimation.py
│   ├── postprocess.py
│   └── export.py
├── configs/
└── tests/
```

## セットアップ手順（ドラフト）
1. Python 仮想環境を作成: `python -m venv .venv && source .venv/bin/activate`
2. 依存ライブラリをインストール: 後日 `requirements.txt` を追加予定
3. サンプルデータを `data/raw/` 配下に配置
4. ノートブックまたはスクリプトを実行し、姿勢推定モデルの動作を確認

## ロードマップ（例）
- [ ] ベースライン姿勢推定モデルの選定と推論スクリプト作成
- [ ] データ前処理・後処理パイプラインの整備
- [ ] ラベルスキーマとメタデータ設計
- [ ] 品質評価指標と可視化ツールの実装
- [ ] CI/CD による自動テスト・バリデーション導入

## コントリビューション
スタイルガイドやテスト方針を整備するまでは、まず Issue でディスカッションしてください。

## ライセンス
利用予定のデータソースやモデルライセンスに合わせたライセンスを検討中。決定次第更新。
